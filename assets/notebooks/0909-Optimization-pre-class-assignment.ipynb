{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to successfully complete this assignment you must do the required reading, watch the provided videos and complete all instructions.  The embedded survey form must be entirely filled out and submitted on or before **11:59pm on Wednesday September 9**.  Students must come to class the next day prepared to discuss the material covered in this assignment. answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Class Assignment: Optimization\n",
    "\n",
    "We define Optimization to be a class of problems that try to find the \"best\" solution over a range of possible solutions.  Typically \"best\" means finding the maximum (or minimum) value of some sort of calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals for today's pre-class assignment \n",
    "\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "1. [What are we trying to optimize?](#What_are_we_trying_to_optimize)\n",
    "1. [Common Optimization Approaches](#Common_Optimization_Approaches)\n",
    "3. [Git Branching](#git_branching)\n",
    "4. [Assignment wrap-up](#Assignment_wrap-up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name=\"What_are_we_trying_to_optimize\"></a>\n",
    "# 1. What are we trying to optimize?\n",
    "\n",
    "The following are some example optimization problems we may use in computational and data sciences. \n",
    "\n",
    "* **Mathematical Models:** Often in science we have designed a mathematical model which we then try to fit to experimental data. Sometimes this can be done directly (regression) but often requires trying different parameters. Model optimization (also called parameter optimization) is the process of searching through the model parameters to find the best ones that fit the data.  \n",
    "\n",
    "* **Machine Learning:** In Machine learning where we have a set of input data that correspond to expected outputs and we use the input/output data to \"train\" machine learning algorithms and minimize the error between the estimated output and the true output. These models tend to be more general (like neural networks) such that the algorithms not only search the parameters of the mathematical models but such over different models themselves. \n",
    "\n",
    "* **Hyperparameter Optimization:** Algorithms can often have lots of input options that \"tune\" how the algorithm performs on a particular problem.  [Hyperparameter optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization) is the process of searching though all of these tunable parameters to find one that allow for best performance of the algorithm. They are called hyperparameter when the algorithms that are being optimized are machine learning algorithms that can be doing their own optimization (i.e. we are trying to learn the best machine learning algorithm). I like the term meta-optimization but that is just me. \n",
    "\n",
    "* **Algorithmic Performance Optimization:** Another common application of optimization in computational and data science is optimizing the performance of an algorithm. Typically this means speeding up the calculations but may also include optimizing for resources such as computer memory.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name=\"Common_Optimization_Approaches\"></a>\n",
    "\n",
    "# 2.  Common Optimization Approaches\n",
    "When setting up an optimization problem there are two major factors that need to be consider. First, how is the \"search space\" defined for the problem and second, what is the \"fitness\" function that is being optimized.  For the purposes of this class we will consider the following example where we want to minimize the function $3x^2 - 10x + 4$ over the range [-10,10].\n",
    "\n",
    "Let's consider the following approaches:\n",
    "\n",
    "- [Analytic solutions](#Analytic_solutions)\n",
    "- [Brute Force Methods](#Brute_Force_Methods)\n",
    "- [Iterative Methods](#Iterative_Methods)\n",
    "- [Random_Methods](#Random_Methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Analytic_solutions\"></a>\n",
    "## Analytic solutions\n",
    "\n",
    "Remember from basic calculus, if the search space for your problem can be represented as a analytic function $f$ that is being minimized it may be possible to directly calculate the minimum of that function.  First you would need to calculate the value of the function at the search space boundaries and then compare the boundary values with the values for which the derivative of $f$ is zero. \n",
    "\n",
    "For more on this see [Mimimization and Maximization Refresher](https://mathinsight.org/minimization_maximization_refresher).\n",
    "\n",
    "Although a powerful approach, analytic solutions only tend to work with problems that have a search space that are mathematically well defined. \n",
    "\n",
    "We will use symbolic python (```sympy```) for this analitic example.  I don't have a great video on sympy but some of you may find the following video interesting. \n",
    "\n",
    "\n",
    "&#9989; **<font color=red>DO THIS:</font>** Watch the following video.  It is a little long but explains how to make Math look good in videos and has a short example of ```sympy``` (You may want to watch this one at double the speed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"qgSa7n_zQ3A\",width=640,height=320, cc_load_policy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Following cell uses symbolic python library to represent a simple parabola and then find the minimum by solving for when the derivative is equal to zero. First we define our symbols and our function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import sympy as sym\n",
    "sym.init_printing()\n",
    "x = sym.symbols('x')\n",
    "y = 3*x**2 - 10*x + 4\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the function over the default range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p1 = sym.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the first derivative using the ```diff``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = sym.diff(y)\n",
    "dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve for ```x``` analytically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sym.solve(dy,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Brute_Force_Methods\"></a>\n",
    "\n",
    "## Brute Force Methods\n",
    "\n",
    "Assuming there is no easy analytic solution. Probably the most straightforward approach to finding the best solution is to use brute force methods which try to calculate all possible solutions and then pick the one that is the best. These methods require considerable computation power and are only feasible for small problems.  \n",
    "\n",
    "&#9989; **<font color=red>DO THIS:</font>** Please watch this video on the basics of ```numpy```. This is included as a review to people still new to python and numpy.  Feel free to skip or run at double speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"_hbWtNgstlI\",width=640,height=320, cc_load_policy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-10,10,1000)\n",
    "y = 3*x**2 - 10*x + 4\n",
    "plt.plot(x,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argmin(y)\n",
    "x[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Iterative_Methods\"></a>\n",
    "## Iterative Methods\n",
    "\n",
    "(Note: This section is a review of Gradient Decent (A type of optimization) from [1102_NN_in-class-assignment](1102_NN_in-class-assignment.ipynb) where we talked about Neural Networks.)\n",
    "\n",
    "\n",
    "Gradient Decent is an example of an iterative method.  For iterative methods you start by making some sort of guess as to the \"best\" solution and then refine the guess with better and better solutions.\n",
    "\n",
    ">Gradient descent is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function. This iterative minimization is achieved using calculus, taking steps in the negative direction of the function gradient.\n",
    "\n",
    "From: https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "def show_animation(delay=0.01):\n",
    "    fig = plt.gcf()\n",
    "    time.sleep(delay)       # Sleep for half a second to slow down the animation\n",
    "    clear_output(wait=True) # Clear output for dynamic display\n",
    "    display(fig)            # Reset display\n",
    "    fig.clear()             # Prevent overlapping and layered plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the function (parabola)\n",
    "def f1(x):\n",
    "    return 3*x**2 - 10*x + 4\n",
    "\n",
    "#Derivative of F1 (also called the gradient)\n",
    "def grad_f1(x):\n",
    "    return 6*x - 10\n",
    "\n",
    "# Choose the x points\n",
    "x = np.array([i for i in range(-1000, 1000)])\n",
    "\n",
    "#Plot the funciton\n",
    "plt.plot(x, f1(x))\n",
    "plt.ylim(-10,100)\n",
    "plt.xlim(-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Gradient Decent\n",
    "\n",
    "x0 = 7                                 # starting point for gradient descent\n",
    "eta = 0.05                             # step size (a.k.a learning rate)\n",
    "p = .0001                              # chosen precision\n",
    "maxIter = 30                           # maximum number of iterations\n",
    "\n",
    "former_min = x0\n",
    "iterative_mins = [former_min]\n",
    "iterCounter = 1\n",
    "\n",
    "while True:\n",
    "    new_min = former_min - eta * grad_f1(former_min)\n",
    "    \n",
    "    iterative_mins.append(new_min)\n",
    "    if abs(former_min - new_min) <= p:\n",
    "        print('Local min of function is %f' %new_min)\n",
    "        print('Number of iterations: %d' %iterCounter)\n",
    "        break\n",
    "    else:\n",
    "        former_min = new_min\n",
    "        \n",
    "    if iterCounter == maxIter:\n",
    "        print('Local min not reached')\n",
    "        break\n",
    "    else:\n",
    "        iterCounter += 1       \n",
    "\n",
    "    plt.figure(0)\n",
    "    plt.plot(x, f1(x), lw=3)\n",
    "    plt.ylim(-10,100)\n",
    "    plt.xlim(-10,10)\n",
    "    plt.title('Iterative descent to minimum:'+str(new_min))\n",
    "    plt.plot(iterative_mins, f1(np.array(iterative_mins)), marker='o')\n",
    "    show_animation(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterative_mins)\n",
    "plt.title(\"Iterative change in minimum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Random_Methods\"></a>\n",
    "## Random Methods\n",
    "\n",
    "Also called [Monte Carlo methods](https://en.wikipedia.org/wiki/Monte_Carlo_method), random methods are just that, random. These methods randomly start and different points within a search space. With enough random samples distributed across the search space we may be able to assume (for some problems) that we found a good solution. Monte Carlo Methods are often combined with iterative methods to come up with fairly robust solutions (there is no guarantee of optimality). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "searchspace = [-10,10]\n",
    "best_y = 100000\n",
    "best_x = []\n",
    "for i in range(1000):\n",
    "    x = uniform(-10,10)\n",
    "    y = 3*x**2 - 10*x + 4\n",
    "    if y < best_y:\n",
    "        best_y = y\n",
    "        best_x = x\n",
    "best_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name=\"Optimization Libraries\"></a>\n",
    "# 3. Optimization Libraries\n",
    "\n",
    "There is no one \"correct\" optimization method for all problems.  You need to pick the method that best fits the problem at hand. The```SciPy``` module has an optimization library built in. Explore what it can do using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimize.show_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>DO THIS:</font>**  See if you can figure out how to use the optimization library to solve the example problem provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** Why do you think these automated solution libraries (ex: ```scipy.optimize```) do not work well for the problem of Algorithmic Performance Optimization?  What is special about performance optimization that makes it particularly hard to optimize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here. Think about your answer and come to class ready to discuss your thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name=\"git_branching\"></a>\n",
    "\n",
    "# 3. Git Branching\n",
    "\n",
    "If you have not already done this, now is a good time to review the following videos which talk about git branching. It is generally good practice to make changes in a branch instead of working from the master branch.   Please review the following videos and come to class ready to practice branching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git Branching https://www.youtube.com/playlist?list=PLqPfbT7gwVP_AlE6HeDQUJsG4nUbGyeh3\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"X0jbrdemjjs\",width=640,height=360, cc_load_policy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging a Branching https://www.youtube.com/playlist?list=PLqPfbT7gwVP_AlE6HeDQUJsG4nUbGyeh3\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"Byp7TFk5jYw\",width=640,height=360, cc_load_policy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>DO THIS:</font>** Using your existing course repository or clone it again and start from scratch.  Create a branch and commit all of the jupyter notebooks for the class up to this point.  Use this branch for all of your notes in class and leave the master branch prestene.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name=\"Assignment_wrap-up\"></a>\n",
    "# 4. Assignment wrap-up\n",
    "\n",
    "Please fill out the form that appears when you run the code below.  **You must completely fill this out in order to receive credit for the assignment!**\n",
    "\n",
    "[Direct Link to Google Form](https://cmse.msu.edu/cmse802-pc-survey)\n",
    "\n",
    "\n",
    "If you have trouble with the embedded form, please make sure you log on with your MSU google account at [googleapps.msu.edu](https://googleapps.msu.edu) and then click on the direct link above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Assignment-Specific QUESTION:</font>** Where you able to get the optimization library to work for the simple example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>**  Summarize what you did in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>**  What questions do you have, if any, about any of the topics discussed in this assignment after working through the jupyter notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>**  How well do you feel this assignment helped you to achieve a better understanding of the above mentioned topic(s)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** What was the **most** challenging part of this assignment for you? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** What was the **least** challenging part of this assignment for you? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>**  What kind of additional questions or support, if any, do you feel you need to have a better understanding of the content in this assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>**  Do you have any further questions or comments about this material, or anything else that's going on in class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** Approximately how long did this pre-class assignment take?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\n",
    "\"\"\"\n",
    "<iframe \n",
    "\tsrc=\"https://cmse.msu.edu/cmse802-pc-survey?embedded=true\" \n",
    "\twidth=\"100%\" \n",
    "\theight=\"1200px\" \n",
    "\tframeborder=\"0\" \n",
    "\tmarginheight=\"0\" \n",
    "\tmarginwidth=\"0\">\n",
    "\tLoading...\n",
    "</iframe>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### Congratulations, we're done!\n",
    "\n",
    "To get credit for this assignment you must fill out and submit the above survey form on or before the assignment due date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course Resources:\n",
    "\n",
    "\n",
    "- [Website](https://msu-cmse-courses.github.io/cmse802-f20-student/)\n",
    "- [ZOOM](https://msu.zoom.us/j/97272546850)\n",
    "- [Syllabus](https://docs.google.com/document/d/e/2PACX-1vT9Wn11y0ECI_NAUl_2NA8V5jcD8dXKJkqUSWXjlawgqr2gU5hII3IsE0S8-CPd3W4xsWIlPAg2YW7D/pub)\n",
    "- [Schedule](https://docs.google.com/spreadsheets/d/e/2PACX-1vQRAm1mqJPQs1YSLPT9_41ABtywSV2f3EWPon9szguL6wvWqWsqaIzqkuHkSk7sea8ZIcIgZmkKJvwu/pubhtml?gid=2142090757&single=true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writen by Dirk Colbry, Michigan State University\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
